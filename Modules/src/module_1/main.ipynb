{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efc2ac2-7570-41c6-a438-82fa85bf25a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating compensation elements and running checks on data\n",
      "Property of Lens Consulting & Lens Digital\n",
      "Release version: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All the variables are imported from LP.py file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side, numbers\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import re\n",
    "import difflib\n",
    "import time\n",
    "import shutil\n",
    "from openpyxl import utils\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning, lineno=329, append=False)\n",
    "warnings.filterwarnings('ignore', message='The behavior of DataFrame concatenation with empty or all-NA entries is deprecated.*',\n",
    "                       category=FutureWarning)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Go up one level from current directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent_dir)\n",
    "from LP import *\n",
    "\n",
    "print('Calculating compensation elements and running checks on data\\nProperty of Lens Consulting & Lens Digital\\nRelease version: 1.0\\n\\n')\n",
    "\n",
    "# Creating a list for files with issues\n",
    "unprocessed_files = {}\n",
    "\n",
    "# Initialize ultimate df\n",
    "ultimate_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "fact_sti_threshold = 0.05\n",
    "\n",
    "# Additional columns from General Info sheet from the SDFs\n",
    "additional_cols = [gi_sector, gi_origin, gi_headcount_cat, gi_revenue_cat, gi_contact_name, \n",
    "                   gi_title, gi_tel, gi_email, 'SDF Language']\n",
    "\n",
    "expected_columns = expected_columns_rus\n",
    "\n",
    "# Setting the columns in the final df\n",
    "final_cols = expected_columns + additional_cols\n",
    "\n",
    "# Creating the final df\n",
    "ultimate_df = pd.DataFrame(columns=final_cols)\n",
    "\n",
    "\n",
    "# Function to enter the file paths\n",
    "def get_valid_path(prompt):\n",
    "    while True:\n",
    "        path = input(prompt)\n",
    "        path = path.replace(\"\\\\\", \"/\")  # Replace backslashes with forward slashes\n",
    "        if os.path.isdir(path):\n",
    "            return path\n",
    "        else:\n",
    "            print(\"Invalid path. Please try again.\")\n",
    "\n",
    "\n",
    "# input_folder = get_valid_path(\"Please enter the path to the input folder: \")\n",
    "# output_folder = get_valid_path(\"Please enter the path to the output folder: \")\n",
    "input_folder = 'companies/rus'\n",
    "output_folder = 'output'\n",
    "print(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29957e92",
   "metadata": {},
   "source": [
    "## Модуль 1. Техническая проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b79503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(error_messages)\n",
    "# добавить проверку на выпадающий список в check_general_info\n",
    "# [\"Missed columns in Data\"] указать какие именно\n",
    "# добавить проверку  Название должности\n",
    "# в expectation_normalization при невозможности нормализовать - удалить\n",
    "# upd: general info уже есть на платформе\n",
    "# сделать тесткейсы для юнит-тестов\n",
    "# добавить в проверки английские слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244d857",
   "metadata": {},
   "source": [
    "### Функции для проверок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6cf90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def man_emp_normalization(text: str, index) -> str:\n",
    "    global errors\n",
    "\n",
    "    # print(\"index: \", index)\n",
    "    if not text or text == 'nan':\n",
    "        errors['data_errors'] += [man_emp, index]\n",
    "        return text\n",
    "\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    managers = [\"руководитель\", \"руководители\", \"менеджер\", \"менеджеры\", \"manager\", \"managers\"]\n",
    "    specialists = [\"рабочий\", \"рабочие\", \"служащий\", \"служащие\", \"специалист\", \"специалисты\", \"specialist\", \"specialists\"]\n",
    "\n",
    "    all_keywords = managers + specialists\n",
    "    words = re.findall(r\"\\w+\", text)\n",
    "\n",
    "    for word in words:\n",
    "        match = difflib.get_close_matches(word, all_keywords, n=1, cutoff=0.7)\n",
    "        if match:\n",
    "            if match[0] in managers:\n",
    "                return \"Руководитель\"\n",
    "            elif match[0] in specialists:\n",
    "                return \"Специалист\"\n",
    "\n",
    "    errors['data_errors'] += [man_emp, index]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf28839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_normalization(text: str, index: int) -> str:\n",
    "    global errors\n",
    "    valid = [\"Соответствует ожиданиям\", \"Ниже ожиданий\", \"Выше ожиданий\"]\n",
    "    valid_eng = ['Meet expectations', 'Below expectations', 'Above expectations']\n",
    "\n",
    "    if not text or text.strip() == '' or text == 'nan':\n",
    "        return '-'\n",
    "\n",
    "    text = text.strip().lower()\n",
    "    match = difflib.get_close_matches(text, [v.lower() for v in valid], n=1, cutoff=0.6)\n",
    "    match_eng = difflib.get_close_matches(text, [v.lower() for v in valid_eng], n=1, cutoff=0.6)\n",
    "\n",
    "    if match:\n",
    "        for v in valid:\n",
    "            if v.lower() == match[0]:\n",
    "                return v\n",
    "    elif match_eng:\n",
    "        for ind in range(len(valid_eng)):\n",
    "            if valid_eng[ind].lower() == match_eng[0]:\n",
    "                return valid[ind]\n",
    "    else:\n",
    "        errors['data_errors'] += [performance, index]\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f47b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_normalization(value, index) -> str:\n",
    "    \"\"\"\n",
    "    Преобразует значение в формат 'N-X' (где X от 1 до 20)\n",
    "    \"\"\"\n",
    "    global errors\n",
    "    if value is not None:\n",
    "        text = str(value).strip().upper()\n",
    "        # Число из строки вроде 'N-3', 'n3', '3'\n",
    "        match = re.search(r'(\\d{1,2})', text)\n",
    "        if match:\n",
    "            num = int(match.group(1))\n",
    "            if 1 <= num <= 20:\n",
    "                return f\"N-{num}\"\n",
    "    \n",
    "    errors['data_errors'] += [n_level, index]\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7709958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_monthly_salaries_normalization(num, index):\n",
    "    global errors\n",
    "\n",
    "    if pd.isna(num) or num == '':\n",
    "        num = 12\n",
    "    elif num < 12 or num > 15:\n",
    "        errors['data_errors'] += [number_monthly_salaries, index]\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d316681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_normalization(text: str, index: int) -> str:\n",
    "    global errors\n",
    "\n",
    "    if text == '' or text == 'nan':\n",
    "        error_messages += [gender_id, index]\n",
    "        return text\n",
    "\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    woman = [\"female\", \"женский\", \"жен\", \"f\", \"ж-й\", 'ж', 'женщина']\n",
    "    man = [\"male\", \"мужской\", \"муж\", \"m\", \"м-й\", 'м', 'мужчина']\n",
    "\n",
    "    all_keywords = woman + man\n",
    "    words = re.findall(r\"\\w+\", text)\n",
    "\n",
    "    for word in words:\n",
    "        match = difflib.get_close_matches(word, all_keywords, n=1, cutoff=0.7)\n",
    "        if match:\n",
    "            if match[0] in woman:\n",
    "                return \"Ж\"\n",
    "            elif match[0] in man:\n",
    "                return \"М\"\n",
    "\n",
    "    error_messages += [gender_id, index]\n",
    "    return text\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb70ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_normalization(text: str, index: int) -> str:\n",
    "    global errors\n",
    "\n",
    "    not_missing = not pd.isna(text)\n",
    "    in_dict_values = text in (set(final_region.values()))\n",
    "    \n",
    "    if not(not_missing and in_dict_values):\n",
    "        error_messages += [region, index]\n",
    "\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8cde3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_some_columns_to_numeric(df):\n",
    "    # Defining columns where ',' will be replaced with '.' so that it is recognized as a number\n",
    "    columns_to_numeric = [monthly_salary, salary_rate, number_monthly_salaries, fact_sti, fact_lti, target_lti_per, additional_pay]\n",
    "    \n",
    "    for column in columns_to_numeric:\n",
    "        df[column] = df[column].astype(str).str.replace(',', '.').str.replace(u'\\xa0', '')\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "        df[column] = df[column].replace('nan', np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91f0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_some_columns_to_str(df):\n",
    "    columns_to_str = [gender_id, sti_eligibility, lti_eligibility, expat, performance]\n",
    "    for column in columns_to_str:\n",
    "        df[column] = df[column].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e067a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign values based on a mapping\n",
    "def translate_values(df, columns, translation_map):\n",
    "    \"\"\"\n",
    "    Translate values in specified DataFrame column(s) using a provided mapping dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    columns: str or list of str, column name(s) to translate\n",
    "    translation_map: dict, mapping of original values to translated values\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with translated values\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Ensure columns is a list for uniform processing\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Apply translation to each specified column\n",
    "    for col in columns:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].map(translation_map).fillna(df_copy[col])\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def map_column_values(df, check_column, amend_column, mapping_dict):\n",
    "    \"\"\"\n",
    "    Check values in one column and assign mapped values to another column.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    check_column: str, name of the column to check values in\n",
    "    amend_column: str, name of the column to assign mapped values to\n",
    "    mapping_dict: dict, mapping of check_column values to amend_column values\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with amended values\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Check if both columns exist\n",
    "    if check_column not in df_copy.columns:\n",
    "        print(f\"Warning: Check column '{check_column}' not found in DataFrame\")\n",
    "        return df_copy\n",
    "    \n",
    "    if amend_column not in df_copy.columns:\n",
    "        print(f\"Warning: Amend column '{amend_column}' not found in DataFrame\")\n",
    "        return df_copy\n",
    "    \n",
    "    # Map values from check_column to amend_column\n",
    "    df_copy[amend_column] = df_copy[check_column].map(mapping_dict).fillna(df_copy[amend_column])\n",
    "    \n",
    "    return df_copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d6c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_to_rus(df):\n",
    "    # Apply translations using the tranlsation function | Converting English version to Russian\n",
    "    df = translate_values(df, [expat, sti_eligibility, lti_eligibility], yes_no_map)\n",
    "    df = translate_values(df, man_emp, manager_spec_map)\n",
    "    df = translate_values(df, performance, performance_map)\n",
    "    df = translate_values(df, gender_id, gender_map)\n",
    "    df = translate_values(df, region, region_match_map)\n",
    "    df = translate_values(df, tenure, tenure_map)\n",
    "    df = translate_values(df, [lti_prog_1, lti_prog_2, lti_prog_3], lti_map)\n",
    "    df = translate_values(df, gi_sector, sector_map)\n",
    "    df = translate_values(df, gi_origin, origin_map)\n",
    "    df = translate_values(df, gi_revenue_cat, revenue_map)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb1db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_rate_normalization(num: int, index: int) -> str:\n",
    "    global errors\n",
    "\n",
    "    if not num or pd.isna(num):\n",
    "        num = 1\n",
    "    elif num >= 1.5 or num <= 0:\n",
    "            error_messages += [salary_rate, index]\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b41587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_pay_normalization(value, index):\n",
    "    global errors\n",
    "\n",
    "    if pd.isna(value):\n",
    "        if region in regions_with_surcharges:\n",
    "            errors['data_errors'] += [additional_pay, index]\n",
    "    elif value < 0:\n",
    "        errors['data_errors'] += [additional_pay, index]\n",
    "\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a17144aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eligibility_normalization(fact, target, value, index):\n",
    "    if not pd.isna(value):\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        if value in ['да', 'д', 'yes', 'y']:\n",
    "            return \"Да\"\n",
    "        else:\n",
    "            return \"Нет\"\n",
    "\n",
    "    else:\n",
    "        if not(pd.isna(fact) or target=='nan'):\n",
    "            return \"Да\"\n",
    "        else:\n",
    "            return \"Нет\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ceeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_sti_normalization(eligibility, value, index):\n",
    "    if eligibility == 'Нет' and not pd.isna(value):\n",
    "        # print(f\"value: {value}, eligibility: {eligibility}\")\n",
    "        errors['data_errors'] += [fact_sti, index]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "811d31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка листа \"Общая информация\"\n",
    "def check_general_info(df_company, lang, df):\n",
    "    global errors\n",
    "    # Setting columns names to the russian version\n",
    "    df.columns = expected_columns_rus\n",
    "    try: #добавить проверку на выпадающий список\n",
    "        df[company_name] = df_company.iloc[0, 1]\n",
    "        df[gi_company_name] = df_company.iloc[0, 1]\n",
    "        df[gi_sector] = df_company.iloc[1, 1]\n",
    "        df[gi_origin] = df_company.iloc[2, 1]\n",
    "        df[gi_headcount_cat] = df_company.iloc[3, 1]\n",
    "        df[gi_revenue_cat] = df_company.iloc[4, 1]\n",
    "        df[gi_contact_name] = df_company.iloc[5, 1]\n",
    "        df[gi_title] = df_company.iloc[6, 1]\n",
    "        df[gi_tel] = df_company.iloc[7, 1]\n",
    "        df[gi_email] = df_company.iloc[8, 1]\n",
    "    except (IndexError, KeyError):\n",
    "        errors['info_errors'] += [\"Incorrect General Info\"]\n",
    "\n",
    "    # print(x for x in df)\n",
    "    if any(x is None or str(x).strip() == \"\" for x in df):\n",
    "        errors['info_errors'] += [\"Incorrect General Info\"]\n",
    "    else:\n",
    "        comp_name = df[company_name][0]\n",
    "        if not re.fullmatch(r\"[A-Za-z_]+\", str(comp_name)):\n",
    "            errors['info_errors'] += [f\"Incorrect company name format: {comp_name}\"]\n",
    "            # print(df[gi_company_name\n",
    "\n",
    "    df['SDF Language'] = lang\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b995d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_sti_normalization(text: str, index: int) -> str:\n",
    "    # Оставлять ли проценты\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lti_checks(main_lti, lti_1, lti_2, lti_3, index, type_lti):\n",
    "    if not ((main_lti == (lti_1 + lti_2 + lti_3)) | main_lti.isna()):\n",
    "        errors['data_errors'] += [type_lti, index]\n",
    "    return main_lti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e7da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978d14a5",
   "metadata": {},
   "source": [
    "### Проверка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff926437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_process_data(df):\n",
    "\n",
    "    df = convert_some_columns_to_numeric(df)\n",
    "    df = convert_some_columns_to_str(df)\n",
    "    df = eng_to_rus(df)\n",
    "    \n",
    "    # Название должности\n",
    "    count_job_title = 0\n",
    "    \n",
    "    # Руководитель/специалист\n",
    "    df[man_emp] = df.apply(lambda x: man_emp_normalization(x[man_emp], x.name), axis=1)\n",
    "    # Оценка эффективности работы сотрудника\n",
    "    df[performance] = df.apply(lambda x: expectation_normalization(x[performance], x.name), axis=1)\n",
    "    # Уровень подчинения по отношению к Первому лицу компании\n",
    "    df[n_level] = df.apply(lambda x: level_normalization(x[n_level], x.name), axis=1)\n",
    "    # Пол\n",
    "    df[gender_id] = df.apply(lambda x: gender_normalization(x[gender_id], x.name), axis=1)\n",
    "    # Регион/область (заполняется автоматически)\n",
    "    df[region] = df[region].astype(str).str.lower()\n",
    "    df = translate_values(df, region, final_region)\n",
    "    df[macroregion] = np.nan\n",
    "    df = map_column_values(df, region, macroregion, region_to_macroregion_map)\n",
    "    df[region] = df.apply(lambda x: region_normalization(x[region], x.name), axis=1)\n",
    "    # Размер ставки\n",
    "    df[salary_rate] = df.apply(lambda x: salary_rate_normalization(x[salary_rate], x.name), axis=1)\n",
    "    # Ежемесячный оклад\n",
    "    df[monthly_salary] = df.dropna(subset=[monthly_salary], inplace=True)\n",
    "    # Число окладов в году\n",
    "    df[number_monthly_salaries] = df.apply(lambda x: number_monthly_salaries_normalization(x[number_monthly_salaries], x.name), axis=1)\n",
    "    # Постоянные надбавки и доплаты (общая сумма за год)\n",
    "    df[additional_pay] = df.apply(lambda x: additional_pay_normalization(x[additional_pay], x.name), axis=1)\n",
    "    # Право на получение переменного вознаграждения\n",
    "    df[sti_eligibility] = df.apply(lambda x: eligibility_normalization(x[fact_sti], x[target_sti], x[sti_eligibility], x.name), axis=1)\n",
    "    # Фактическая премия\n",
    "    df[fact_sti] = df.apply(lambda x: fact_sti_normalization(x[sti_eligibility], x[fact_sti], x.name), axis=1)\n",
    "    # Целевая премия (%)\n",
    "    df[target_sti] = df.apply(lambda x: target_sti_normalization(x[target_sti], x.name), axis=1)\n",
    "    # Фактическая стоимость всех предоставленных типов LTI за 1 год (AK)\n",
    "    df[fact_lti] = df.apply(lambda x: lti_checks(x[fact_lti], x[fact_lti_1], x[fact_lti_2], x[fact_lti_3], x.name, fact_lti))\n",
    "    # Целевая стоимость всех предоставленных типов LTI в % от базового оклада за 1 год\n",
    "    df[target_lti_per] = df.apply(lambda x: lti_checks(x[target_lti_per], x[target_lti_1], x[target_lti_2], x[target_lti_3], x.name, target_lti_per))\n",
    "    # Целевая стоимость вознаграждения  как % от базового оклада [Данные] AO, AS, AW\n",
    "    \n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1694a54c-7aee-492e-a7d9-231157cb2c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1: 3Logic_Group_Salary data_rus_2025.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s_ivc\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\s_ivc\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed in: 0.8864121437072754\n",
      "\n",
      "\n",
      "==================== WARNING! ====================\n",
      "List of unprocessed files:\n",
      "File: 3Logic_Group_Salary data_rus_2025.xlsx, Issue: {'info_errors': ['Incorrect company name format: 3Logic_Group'], 'data_errors': []}\n",
      "\n",
      "Copying 1 unprocessed files to 'unprocessed' folder...\n",
      "Copied: 3Logic_Group_Salary data_rus_2025.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Проверка каждого файла на наличие всех нужных колонок. При любой ошибке файл попадает в unprocessed.\n",
    "start_time = time.time()\n",
    "# Seeting the counter for the files\n",
    "counter = 0\n",
    "# Iterate through all the files in the input folder\n",
    "process_start = time.time()\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    # Check if the file is an Excel file\n",
    "    if file.endswith('.xlsx') or file.endswith('.xls') or file.endswith('.xlsm'):\n",
    "        counter += 1\n",
    "        errors = {\n",
    "            'info_errors': [], # Список ошибок\n",
    "            'data_errors': [] # Cписок (row, col)\n",
    "        }\n",
    "        # try:\n",
    "        print(f\"Processing file {counter}: {file}\")\n",
    "        # Process the Excel file\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "\n",
    "        # Language detection\n",
    "        if 'Salary Data' in pd.ExcelFile(file_path).sheet_names:\n",
    "            lang = 'ENG'\n",
    "            rm_data = rem_data_eng \n",
    "            cmp_data = company_data_eng\n",
    "        else:\n",
    "            lang = 'RUS'\n",
    "            rm_data = rem_data\n",
    "            cmp_data = company_data\n",
    "        expected_columns = set_expected_columns(lang)\n",
    "\n",
    "        # Exporting the dataframe from an excel file\n",
    "        # For SDFs\n",
    "        df = pd.read_excel(file_path, sheet_name=rm_data, header=6)\n",
    "\n",
    "        # Apply cleaning to column names\n",
    "        df.columns = [re.sub(r'\\s+', ' ', str(col).replace('\\n', ' ').replace('\\r', ' ')).strip() \n",
    "                        for col in df.columns]\n",
    "        \n",
    "        # Check if all expected columns are present\n",
    "        missing_columns_rem_data = [col for col in expected_columns if col not in df.columns]\n",
    "\n",
    "        if missing_columns_rem_data:\n",
    "            # If any columns are missing, skip this file\n",
    "            unprocessed_files[os.path.basename(file_path)] = missing_columns_rem_data\n",
    "            errors['info_errors'] += [\"Missed columns in Data\"] # указать какие именно\n",
    "            # continue\n",
    "        \n",
    "        # leaving only required columns\n",
    "        df = df[expected_columns]\n",
    "\n",
    "        rows_to_drop = [company_name, job_title]\n",
    "    \n",
    "        # Cleaning all the blanks from the columns\n",
    "        for column in rows_to_drop:\n",
    "            df[column] = df[column].replace('', np.nan)\n",
    "\n",
    "        # Dropping rows where company name and title are empty at the same time\n",
    "        df.dropna(subset=[company_name, job_title], how = 'all', inplace=True)\n",
    "\n",
    "        df_company = pd.read_excel(file_path, sheet_name=cmp_data, header=1)\n",
    "        df_company = df_company.iloc[:, 2:]\n",
    "\n",
    "        # Taking the data from the General Info sheet\n",
    "        df = check_general_info(df_company, lang, df)\n",
    "        # print(df[man_emp])\n",
    "        df = check_and_process_data(df)\n",
    "        \n",
    "        if errors['data_errors'] == [] and errors['info_errors'] == []:\n",
    "            # Save the processed DataFrame to the output folder\n",
    "            ultimate_df = pd.concat([ultimate_df, df])\n",
    "        else:\n",
    "            unprocessed_files[os.path.basename(file_path)] = errors\n",
    "        \n",
    "        # except Exception as e:\n",
    "            # unprocessed_files[os.path.basename(file_path)] = [str(e)]\n",
    "\n",
    "\n",
    "proces_end = time.time()\n",
    "print(f'Files processed in: {proces_end - process_start}')\n",
    "\n",
    "if len(unprocessed_files) == 0:\n",
    "    print(f\"\\nAll files were processed and concated\")\n",
    "else:\n",
    "    for file, issue in unprocessed_files.items():\n",
    "        print(f'\\n')\n",
    "        print(\"=\" * 20 + \" WARNING! \" + \"=\" * 20)\n",
    "        print(f\"List of unprocessed files:\")\n",
    "        print(f\"File: {file}, Issue: {issue}\")\n",
    "        \n",
    "# Create unprocessed folder if it doesn't exist\n",
    "unprocessed_folder = os.path.join(input_folder, 'unprocessed')\n",
    "os.makedirs(unprocessed_folder, exist_ok=True)\n",
    "\n",
    "# Copy unprocessed files to the unprocessed folder (overwrite if exists)\n",
    "if unprocessed_files:\n",
    "    print(f\"\\nCopying {len(unprocessed_files)} unprocessed files to 'unprocessed' folder...\")\n",
    "\n",
    "    for file_name in unprocessed_files.keys():\n",
    "        source_path = os.path.join(input_folder, file_name)\n",
    "        destination_path = os.path.join(unprocessed_folder, file_name)\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(source_path):\n",
    "                # Если файл уже есть в папке unprocessed — удалим его\n",
    "                if os.path.exists(destination_path):\n",
    "                    os.remove(destination_path)\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to copy {file_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11a711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
