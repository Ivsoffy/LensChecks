{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efc2ac2-7570-41c6-a438-82fa85bf25a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating compensation elements and running checks on data\n",
      "Property of Lens Consulting & Lens Digital\n",
      "Release version: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All the variables are imported from LP.py file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side, numbers\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import re\n",
    "import difflib\n",
    "import time\n",
    "import shutil\n",
    "from openpyxl import utils\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning, lineno=329, append=False)\n",
    "warnings.filterwarnings('ignore', message='The behavior of DataFrame concatenation with empty or all-NA entries is deprecated.*',\n",
    "                       category=FutureWarning)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent_dir)\n",
    "print(sys.path)\n",
    "from LP import *\n",
    "\n",
    "print('Calculating compensation elements and running checks on data\\nProperty of Lens Consulting & Lens Digital\\nRelease version: 1.0\\n\\n')\n",
    "\n",
    "# Function to enter the file paths\n",
    "def get_valid_path(prompt):\n",
    "    while True:\n",
    "        path = input(prompt)\n",
    "        path = path.replace(\"\\\\\", \"/\")  # Replace backslashes with forward slashes\n",
    "        if os.path.isdir(path):\n",
    "            return path\n",
    "        else:\n",
    "            print(\"Invalid path. Please try again.\")\n",
    "\n",
    "\n",
    "# input_folder = get_valid_path(\"Please enter the path to the input folder: \")\n",
    "# output_folder = get_valid_path(\"Please enter the path to the output folder: \")\n",
    "\n",
    "print(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29957e92",
   "metadata": {},
   "source": [
    "## Модуль 1. Техническая проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b79503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавить проверку на выпадающий список в check_general_info\n",
    "# [\"Missed columns in Data\"] указать какие именно\n",
    "# добавить проверку  Название должности\n",
    "# в expectation_normalization при невозможности нормализовать - удалить\n",
    "# upd: general info уже есть на платформе\n",
    "# сделать тесткейсы для юнит-тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244d857",
   "metadata": {},
   "source": [
    "### Функции для проверок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6cf90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def man_emp_normalization(text: str, index) -> str:\n",
    "    global errors\n",
    "\n",
    "    # print(\"index: \", index)\n",
    "    if not text or text == 'nan':\n",
    "        errors['data_errors'] += [(man_emp, index)]\n",
    "        return text\n",
    "\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    managers = [\"руководитель\", \"руководители\", \"менеджер\", \"менеджеры\", \"manager\", \"managers\"]\n",
    "    specialists = [\"рабочий\", \"рабочие\", \"служащий\", \"служащие\", \"специалист\", \"специалисты\", \"specialist\", \"specialists\"]\n",
    "\n",
    "    all_keywords = managers + specialists\n",
    "    words = re.findall(r\"\\w+\", text)\n",
    "\n",
    "    for word in words:\n",
    "        match = difflib.get_close_matches(word, all_keywords, n=1, cutoff=0.7)\n",
    "        if match:\n",
    "            if match[0] in managers:\n",
    "                return \"Руководитель\"\n",
    "            elif match[0] in specialists:\n",
    "                return \"Специалист\"\n",
    "\n",
    "    errors['data_errors'] += [(man_emp, index)]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf28839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_normalization(text: str, index: int) -> str:\n",
    "    global errors\n",
    "    valid = [\"Соответствует ожиданиям\", \"Ниже ожиданий\", \"Выше ожиданий\"]\n",
    "    valid_eng = ['Meet expectations', 'Below expectations', 'Above expectations']\n",
    "\n",
    "    if not text or text.strip() == '' or text == 'nan':\n",
    "        return '-'\n",
    "\n",
    "    text = text.strip().lower()\n",
    "    match = difflib.get_close_matches(text, [v.lower() for v in valid], n=1, cutoff=0.6)\n",
    "    match_eng = difflib.get_close_matches(text, [v.lower() for v in valid_eng], n=1, cutoff=0.6)\n",
    "\n",
    "    if match:\n",
    "        for v in valid:\n",
    "            if v.lower() == match[0]:\n",
    "                return v\n",
    "    elif match_eng:\n",
    "        for ind in range(len(valid_eng)):\n",
    "            if valid_eng[ind].lower() == match_eng[0]:\n",
    "                return valid[ind]\n",
    "    else:\n",
    "        errors['data_errors'] += [(performance, index)]\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f47b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_normalization(value, index) -> str:\n",
    "    \"\"\"\n",
    "    Преобразует значение в формат 'N-X' (где X от 1 до 20)\n",
    "    \"\"\"\n",
    "    global errors\n",
    "    if value is not None:\n",
    "        text = str(value).strip().upper()\n",
    "        # Число из строки вроде 'N-3', 'n3', '3'\n",
    "        match = re.search(r'(\\d{1,2})', text)\n",
    "        if match:\n",
    "            num = int(match.group(1))\n",
    "            if 1 <= num <= 20:\n",
    "                return f\"N-{num}\"\n",
    "    \n",
    "    errors['data_errors'] += [(n_level, index)]\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7709958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_monthly_salaries_normalization(num, index):\n",
    "    global errors\n",
    "\n",
    "    if pd.isna(num) or num == '':\n",
    "        num = 12\n",
    "    elif num < 12 or num > 15:\n",
    "        errors['data_errors'] += [(number_monthly_salaries, index)]\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d316681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_normalization(text: str, index: int) -> str:\n",
    "    global errors\n",
    "\n",
    "    if text == '' or text == 'nan':\n",
    "        errors['data_errors'] += [(gender_id, index)]\n",
    "        return text\n",
    "\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    woman = [\"female\", \"женский\", \"жен\", \"f\", \"ж-й\", 'ж', 'женщина']\n",
    "    man = [\"male\", \"мужской\", \"муж\", \"m\", \"м-й\", 'м', 'мужчина']\n",
    "\n",
    "    all_keywords = woman + man\n",
    "    words = re.findall(r\"\\w+\", text)\n",
    "\n",
    "    for word in words:\n",
    "        match = difflib.get_close_matches(word, all_keywords, n=1, cutoff=0.7)\n",
    "        if match:\n",
    "            if match[0] in woman:\n",
    "                return \"Ж\"\n",
    "            elif match[0] in man:\n",
    "                return \"М\"\n",
    "\n",
    "    errors['data_errors'] += [(gender_id, index)]\n",
    "    return text\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb70ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_normalization(text: str, index: int) -> str:\n",
    "    global errors\n",
    "\n",
    "    not_missing = not pd.isna(text)\n",
    "    in_dict_values = text in (set(final_region.values()))\n",
    "    \n",
    "    if not(not_missing and in_dict_values):\n",
    "        errors['data_errors'] += [(region, index)]\n",
    "\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8cde3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_some_columns_to_numeric(df):\n",
    "    # Defining columns where ',' will be replaced with '.' so that it is recognized as a number\n",
    "    columns_to_numeric = [monthly_salary, salary_rate, number_monthly_salaries, fact_sti, fact_lti, target_lti_per, additional_pay]\n",
    "    \n",
    "    for column in columns_to_numeric:\n",
    "        df[column] = df[column].astype(str).str.replace(',', '.').str.replace(u'\\xa0', '')\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "        df[column] = df[column].replace('nan', np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91f0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_some_columns_to_str(df):\n",
    "    columns_to_str = [gender_id, sti_eligibility, lti_eligibility, expat, performance]\n",
    "    for column in columns_to_str:\n",
    "        df[column] = df[column].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e067a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign values based on a mapping\n",
    "def translate_values(df, columns, translation_map):\n",
    "    \"\"\"\n",
    "    Translate values in specified DataFrame column(s) using a provided mapping dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    columns: str or list of str, column name(s) to translate\n",
    "    translation_map: dict, mapping of original values to translated values\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with translated values\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Ensure columns is a list for uniform processing\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # Apply translation to each specified column\n",
    "    for col in columns:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].map(translation_map).fillna(df_copy[col])\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def map_column_values(df, check_column, amend_column, mapping_dict):\n",
    "    \"\"\"\n",
    "    Check values in one column and assign mapped values to another column.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    check_column: str, name of the column to check values in\n",
    "    amend_column: str, name of the column to assign mapped values to\n",
    "    mapping_dict: dict, mapping of check_column values to amend_column values\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame with amended values\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Check if both columns exist\n",
    "    if check_column not in df_copy.columns:\n",
    "        print(f\"Warning: Check column '{check_column}' not found in DataFrame\")\n",
    "        return df_copy\n",
    "    \n",
    "    if amend_column not in df_copy.columns:\n",
    "        print(f\"Warning: Amend column '{amend_column}' not found in DataFrame\")\n",
    "        return df_copy\n",
    "    \n",
    "    # Map values from check_column to amend_column\n",
    "    df_copy[amend_column] = df_copy[check_column].map(mapping_dict).fillna(df_copy[amend_column])\n",
    "    \n",
    "    return df_copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d6c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_to_rus(df):\n",
    "    # Apply translations using the tranlsation function | Converting English version to Russian\n",
    "    df = translate_values(df, [expat, sti_eligibility, lti_eligibility], yes_no_map)\n",
    "    df = translate_values(df, man_emp, manager_spec_map)\n",
    "    df = translate_values(df, performance, performance_map)\n",
    "    df = translate_values(df, gender_id, gender_map)\n",
    "    df = translate_values(df, region, region_match_map)\n",
    "    df = translate_values(df, tenure, tenure_map)\n",
    "    df = translate_values(df, [lti_prog_1, lti_prog_2, lti_prog_3], lti_map)\n",
    "    df = translate_values(df, gi_sector, sector_map)\n",
    "    df = translate_values(df, gi_origin, origin_map)\n",
    "    df = translate_values(df, gi_revenue_cat, revenue_map)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb1db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_rate_normalization(num: int, index: int) -> str:\n",
    "    global errors\n",
    "\n",
    "    if not num or pd.isna(num):\n",
    "        num = 1\n",
    "    elif num >= 1.5 or num <= 0:\n",
    "            errors['data_errors'] += [(salary_rate, index)]\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b41587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_pay_normalization(value, index):\n",
    "    global errors\n",
    "\n",
    "    if pd.isna(value):\n",
    "        if region in regions_with_surcharges:\n",
    "            errors['data_errors'] += [(additional_pay, index)]\n",
    "    elif value < 0:\n",
    "        errors['data_errors'] += [(additional_pay, index)]\n",
    "\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a17144aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eligibility_normalization(fact, target, value, index):\n",
    "    if not pd.isna(value):\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        if value in ['да', 'д', 'yes', 'y']:\n",
    "            return \"Да\"\n",
    "        else:\n",
    "            return \"Нет\"\n",
    "\n",
    "    else:\n",
    "        if not(pd.isna(fact) or target=='nan'):\n",
    "            return \"Да\"\n",
    "        else:\n",
    "            return \"Нет\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ceeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_sti_normalization(eligibility, value, index):\n",
    "    global errors\n",
    "    if eligibility == 'Нет' and not pd.isna(value):\n",
    "        # print(f\"value: {value}, eligibility: {eligibility}\")\n",
    "        errors['data_errors'] += [(fact_sti, index)]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "811d31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка листа \"Общая информация\"\n",
    "def check_general_info(df_company, lang, df):\n",
    "    global errors\n",
    "    # Setting columns names to the russian version\n",
    "    df.columns = expected_columns_rus\n",
    "    try: #добавить проверку на выпадающий список\n",
    "        df[company_name] = df_company.iloc[0, 1]\n",
    "        df[gi_company_name] = df_company.iloc[0, 1]\n",
    "        df[gi_sector] = df_company.iloc[1, 1]\n",
    "        df[gi_origin] = df_company.iloc[2, 1]\n",
    "        df[gi_headcount_cat] = df_company.iloc[3, 1]\n",
    "        df[gi_revenue_cat] = df_company.iloc[4, 1]\n",
    "        df[gi_contact_name] = df_company.iloc[5, 1]\n",
    "        df[gi_title] = df_company.iloc[6, 1]\n",
    "        df[gi_tel] = df_company.iloc[7, 1]\n",
    "        df[gi_email] = df_company.iloc[8, 1]\n",
    "    except (IndexError, KeyError):\n",
    "        errors['info_errors'] += [\"Incorrect General Info\"]\n",
    "\n",
    "    # print(x for x in df)\n",
    "    if any(x is None or str(x).strip() == \"\" for x in df):\n",
    "        errors['info_errors'] += [\"Incorrect General Info\"]\n",
    "    else:\n",
    "        comp_name = df[company_name][0]\n",
    "        if not re.fullmatch(r\"[A-Za-z_]+\", str(comp_name)):\n",
    "            errors['info_errors'] += [f\"Incorrect company name format: {comp_name}\"]\n",
    "            # print(df[gi_company_name\n",
    "\n",
    "    df['SDF Language'] = lang\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b995d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_sti_normalization(text: str, index: int) -> str:\n",
    "    global errors\n",
    "    # Оставлять ли проценты\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lti_checks(main_lti, lti_1, lti_2, lti_3, index, type_lti):\n",
    "    global errors\n",
    "    if not ((main_lti == (lti_1 + lti_2 + lti_3)) | np.isnan(main_lti)):\n",
    "        errors['data_errors'] += [(type_lti, index)]\n",
    "    return main_lti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_errors_to_excel(errors, input_path, output_path):\n",
    "    \"\"\"Добавляет лист 'Ошибки' и подсвечивает ячейки с ошибками на листе 'Данные'.\"\"\"\n",
    "    # --- Формирование таблицы ошибок ---\n",
    "    info = errors.get('info_errors', [])\n",
    "    data = [col for col, _ in errors.get('data_errors', [])]\n",
    "    unique_data = list(dict.fromkeys(data))\n",
    "    n = max(len(info), len(unique_data))\n",
    "    df_errors = pd.DataFrame({\n",
    "        'info_errors': info + [None] * (n - len(info)),\n",
    "        'data_errors': unique_data + [None] * (n - len(unique_data))\n",
    "    })\n",
    "\n",
    "    wb = load_workbook(input_path, data_only=True)\n",
    "    ws_err = wb.create_sheet(\"Ошибки\", 0)\n",
    "\n",
    "    # --- Запись и оформление листа \"Ошибки\" ---\n",
    "    for r, row in enumerate(dataframe_to_rows(df_errors, index=False, header=True), 1):\n",
    "        for c, v in enumerate(row, 1):\n",
    "            ws_err.cell(r, c, v)\n",
    "\n",
    "    header_style = {\"font\": Font(bold=True, color=\"FFFFFF\"),\n",
    "                    \"fill\": PatternFill(\"solid\", fgColor=\"4472C4\")}\n",
    "    border = Border(*[Side(style=\"thin\", color=\"808080\")]*4)\n",
    "    for cell in ws_err[1]:\n",
    "        cell.font, cell.fill = header_style[\"font\"], header_style[\"fill\"]\n",
    "        cell.alignment, cell.border = Alignment(horizontal='center'), border\n",
    "    for row in ws_err.iter_rows(min_row=2):\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(wrap_text=True, vertical=\"top\")\n",
    "            cell.border = border\n",
    "    for col in ws_err.columns:\n",
    "        ws_err.column_dimensions[col[0].column_letter].width = max(len(str(c.value) or \"\") for c in col) + 2\n",
    "\n",
    "    # --- Определение структуры листа \"Данные\" ---\n",
    "    data_sheet = next((s for s in wb.sheetnames if s.strip().lower() == \"данные\"), None)\n",
    "    if not data_sheet:\n",
    "        raise ValueError(\"Не найден лист 'Данные'.\")\n",
    "    ws_data = wb[data_sheet]\n",
    "    df_head = pd.read_excel(input_path, sheet_name=data_sheet, header=None, nrows=40)\n",
    "\n",
    "    non_empty = df_head.notna().sum(axis=1)\n",
    "    header_end = max((i for i, v in enumerate(non_empty) if v >= max(3, df_head.shape[1] * 0.05)), default=0)\n",
    "    data_start = header_end + 2\n",
    "\n",
    "    def norm(s): return str(s).strip().lower() if pd.notna(s) else \"\"\n",
    "    col_map = {norm(df_head.iat[r, c]): c + 1\n",
    "               for r in range(header_end + 1) for c in range(df_head.shape[1])\n",
    "               if pd.notna(df_head.iat[r, c])}\n",
    "\n",
    "    # --- Подсветка ошибок ---\n",
    "    orange = PatternFill(\"solid\", fgColor=\"FFC000\")\n",
    "    for col_name, idx in errors.get('data_errors', []):\n",
    "        col_idx = col_map.get(norm(col_name))\n",
    "        if not col_idx:\n",
    "            print(f\"Не найдена колонка: {col_name}\")\n",
    "            continue\n",
    "        excel_row = 8 + idx\n",
    "        if 1 <= excel_row <= ws_data.max_row:\n",
    "            ws_data.cell(excel_row, col_idx).fill = orange\n",
    "        else:\n",
    "            print(f\"Строка вне диапазона: {excel_row}\")\n",
    "\n",
    "    wb.save(output_path)\n",
    "    print(f\"Лист 'Ошибки' добавлен, ячейки подсвечены. Файл: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d14a5",
   "metadata": {},
   "source": [
    "### Проверка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff926437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_process_data(df):\n",
    "\n",
    "    df = convert_some_columns_to_numeric(df)\n",
    "    df = convert_some_columns_to_str(df)\n",
    "    df = eng_to_rus(df)\n",
    "    \n",
    "    # Название должности\n",
    "    count_job_title = 0\n",
    "    \n",
    "    # Руководитель/специалист\n",
    "    df[man_emp] = df.apply(lambda x: man_emp_normalization(x[man_emp], x.name), axis=1)\n",
    "    # Оценка эффективности работы сотрудника\n",
    "    df[performance] = df.apply(lambda x: expectation_normalization(x[performance], x.name), axis=1)\n",
    "    # Уровень подчинения по отношению к Первому лицу компании\n",
    "    df[n_level] = df.apply(lambda x: level_normalization(x[n_level], x.name), axis=1)\n",
    "    # Пол\n",
    "    df[gender_id] = df.apply(lambda x: gender_normalization(x[gender_id], x.name), axis=1)\n",
    "    # Регион/область (заполняется автоматически)\n",
    "    df[region] = df[region].astype(str).str.lower()\n",
    "    df = translate_values(df, region, final_region)\n",
    "    df[macroregion] = np.nan\n",
    "    df = map_column_values(df, region, macroregion, region_to_macroregion_map)\n",
    "    df[region] = df.apply(lambda x: region_normalization(x[region], x.name), axis=1)\n",
    "    # Размер ставки\n",
    "    df[salary_rate] = df.apply(lambda x: salary_rate_normalization(x[salary_rate], x.name), axis=1)\n",
    "    # Ежемесячный оклад\n",
    "    df[monthly_salary] = df.dropna(subset=[monthly_salary], inplace=True)\n",
    "    # Число окладов в году\n",
    "    df[number_monthly_salaries] = df.apply(lambda x: number_monthly_salaries_normalization(x[number_monthly_salaries], x.name), axis=1)\n",
    "    # Постоянные надбавки и доплаты (общая сумма за год)\n",
    "    df[additional_pay] = df.apply(lambda x: additional_pay_normalization(x[additional_pay], x.name), axis=1)\n",
    "    # Право на получение переменного вознаграждения\n",
    "    df[sti_eligibility] = df.apply(lambda x: eligibility_normalization(x[fact_sti], x[target_sti], x[sti_eligibility], x.name), axis=1)\n",
    "    # Фактическая премия\n",
    "    df[fact_sti] = df.apply(lambda x: fact_sti_normalization(x[sti_eligibility], x[fact_sti], x.name), axis=1)\n",
    "    # Целевая премия (%)\n",
    "    df[target_sti] = df.apply(lambda x: target_sti_normalization(x[target_sti], x.name), axis=1)\n",
    "    # Фактическая стоимость всех предоставленных типов LTI за 1 год (AK)\n",
    "    print( fact_lti in df.columns)\n",
    "    df[fact_lti] = df.apply(lambda x: lti_checks(x[fact_lti], x[fact_lti_1], x[fact_lti_2], x[fact_lti_3], x.name, fact_lti), axis=1)\n",
    "    # Целевая стоимость всех предоставленных типов LTI в % от базового оклада за 1 год\n",
    "    df[target_lti_per] = df.apply(lambda x: lti_checks(x[target_lti_per], x[target_lti_1], x[target_lti_2], x[target_lti_3], x.name, target_lti_per), axis=1)\n",
    "    # Целевая стоимость вознаграждения  как % от базового оклада [Данные] AO, AS, AW\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1694a54c-7aee-492e-a7d9-231157cb2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка каждого файла на наличие всех нужных колонок. При любой ошибке файл попадает в unprocessed.\n",
    "\n",
    "def main(input_folder='companies/rus', output_folder='output'):\n",
    "    global errors\n",
    "    # Creating a list for files with issues\n",
    "    unprocessed_files = {}\n",
    "\n",
    "    # Initialize ultimate df\n",
    "    ultimate_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    fact_sti_threshold = 0.05\n",
    "\n",
    "    # Additional columns from General Info sheet from the SDFs\n",
    "    additional_cols = [gi_sector, gi_origin, gi_headcount_cat, gi_revenue_cat, gi_contact_name, \n",
    "                    gi_title, gi_tel, gi_email, 'SDF Language']\n",
    "\n",
    "    expected_columns = expected_columns_rus\n",
    "\n",
    "    # Setting the columns in the final df\n",
    "    final_cols = expected_columns + additional_cols\n",
    "\n",
    "    # Creating the final df\n",
    "    ultimate_df = pd.DataFrame(columns=final_cols)\n",
    "    counter = 0\n",
    "    # Iterate through all the files in the input folder\n",
    "    process_start = time.time()\n",
    "    # \n",
    "    for file in os.listdir(input_folder):\n",
    "        # Check if the file is an Excel file\n",
    "        if file.endswith('.xlsx') or file.endswith('.xls') or file.endswith('.xlsm'):\n",
    "            counter += 1\n",
    "            errors = {\n",
    "                'info_errors': [], # Список ошибок\n",
    "                'data_errors': [] # Cписок (row, col)\n",
    "            }\n",
    "            \n",
    "            print(f\"Processing file {counter}: {file}\")\n",
    "            # Process the Excel file\n",
    "            file_path = os.path.join(input_folder, file)\n",
    "\n",
    "            # Language detection\n",
    "            if 'Salary Data' in pd.ExcelFile(file_path).sheet_names:\n",
    "                lang = 'ENG'\n",
    "                rm_data = rem_data_eng \n",
    "                cmp_data = company_data_eng\n",
    "            else:\n",
    "                lang = 'RUS'\n",
    "                rm_data = rem_data\n",
    "                cmp_data = company_data\n",
    "            expected_columns = set_expected_columns(lang)\n",
    "\n",
    "            # Exporting the dataframe from an excel file\n",
    "            # For SDFs\n",
    "            df = pd.read_excel(file_path, sheet_name=rm_data, header=6)\n",
    "\n",
    "            # Apply cleaning to column names\n",
    "            df.columns = [re.sub(r'\\s+', ' ', str(col).replace('\\n', ' ').replace('\\r', ' ')).strip() \n",
    "                            for col in df.columns]\n",
    "            \n",
    "            # Check if all expected columns are present\n",
    "            missing_columns_rem_data = [col for col in expected_columns if col not in df.columns]\n",
    "\n",
    "            if missing_columns_rem_data:\n",
    "                # If any columns are missing, skip this file\n",
    "                # unprocessed_files[os.path.basename(file_path)] = missing_columns_rem_data\n",
    "                errors['info_errors'] += [f\"Missed columns in Data: {missing_columns_rem_data}\"] # указать какие именно\n",
    "                # continue\n",
    "            \n",
    "            # leaving only required columns\n",
    "            df = df[expected_columns]\n",
    "\n",
    "            rows_to_drop = [company_name, job_title]\n",
    "        \n",
    "            # Cleaning all the blanks from the columns\n",
    "            for column in rows_to_drop:\n",
    "                df[column] = df[column].replace('', np.nan)\n",
    "\n",
    "            # Dropping rows where company name and title are empty at the same time\n",
    "            df.dropna(subset=[company_name, job_title], how = 'all', inplace=True)\n",
    "\n",
    "            df_company = pd.read_excel(file_path, sheet_name=cmp_data, header=1)\n",
    "            df_company = df_company.iloc[:, 2:]\n",
    "\n",
    "            # Taking the data from the General Info sheet\n",
    "            df = check_general_info(df_company, lang, df)\n",
    "            # print(df[man_emp])\n",
    "            df = check_and_process_data(df)\n",
    "            \n",
    "            if errors['data_errors'] == [] and errors['info_errors'] == []:\n",
    "                # Save the processed DataFrame to the output folder\n",
    "                ultimate_df = pd.concat([ultimate_df, df])\n",
    "            else:\n",
    "                unprocessed_files[os.path.basename(file_path)] = errors\n",
    "            \n",
    "            # except Exception as e:\n",
    "                # unprocessed_files[os.path.basename(file_path)] = [str(e)]\n",
    "\n",
    "\n",
    "    proces_end = time.time()\n",
    "    print(f'Files processed in: {proces_end - process_start}')\n",
    "\n",
    "    if len(unprocessed_files) == 0:\n",
    "        print(f\"\\nAll files were processed and concated\")\n",
    "    else:\n",
    "        for file, issue in unprocessed_files.items():\n",
    "            # error_df = pd.DataFrame(data=issue)\n",
    "            print(f'\\n')\n",
    "            print(\"=\" * 20 + \" WARNING! \" + \"=\" * 20)\n",
    "            print(f\"List of unprocessed files:\")\n",
    "            print(f\"File: {file}, Issue: {issue}\")\n",
    "            \n",
    "            # print(df_errors)\n",
    "            \n",
    "    # Create unprocessed folder if it doesn't exist\n",
    "    unprocessed_folder = os.path.join(input_folder, 'unprocessed')\n",
    "    os.makedirs(unprocessed_folder, exist_ok=True)\n",
    "\n",
    "    # Copy unprocessed files to the unprocessed folder (overwrite if exists)\n",
    "    if unprocessed_files:\n",
    "        print(f\"\\nCopying {len(unprocessed_files)} unprocessed files to 'unprocessed' folder...\")\n",
    "\n",
    "        for file_name, issue in unprocessed_files.items():\n",
    "            source_path = os.path.join(input_folder, file_name)\n",
    "            destination_path = os.path.join(unprocessed_folder, file_name)\n",
    "            try:\n",
    "                if os.path.exists(source_path):\n",
    "                    # Если файл уже есть в папке unprocessed — удалим его\n",
    "                    if os.path.exists(destination_path):\n",
    "                        os.remove(destination_path)\n",
    "                    add_errors_to_excel(issue, source_path, destination_path)\n",
    "                    # shutil.copy2(source_path, destination_path)\n",
    "                    # print(f\"Copied: {file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {file_name}: {str(e)}\")\n",
    "    \n",
    "    try:\n",
    "        output_path = os.path.join(output_folder, 'Database.xlsx')\n",
    "        with pd.ExcelWriter(output_path) as writer:\n",
    "            ultimate_df.to_excel(writer, index=False, sheet_name='Total Data')\n",
    "        print(f\"Successfully saved Excel file to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save Excel file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f83b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
