
# All the variables are imported from LP.py file
import pandas as pd
from openpyxl import load_workbook
import openpyxl
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side, numbers
import os
import sys
import warnings
import re
from openpyxl import utils
import warnings
import uuid
# warnings.filterwarnings("ignore", category=UserWarning)
warnings.simplefilter("ignore", category=UserWarning, lineno=329, append=False)
warnings.filterwarnings('ignore', message='The behavior of DataFrame concatenation with empty or all-NA entries is deprecated.*',
                       category=FutureWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)

pd.set_option('future.no_silent_downcasting', True)
parent_dir = os.path.dirname(os.getcwd())
sys.path.insert(0, parent_dir)
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from LP import *
from inference_grades import predict_grades

def module_4(input_folder, output_folder, params):
    folder_py = params['folder_past_year']
    already_fixed = params['after_fix']
    
    counter = 0
    found_files=[]
    for file in os.listdir(input_folder):
        # Check if the file is an Excel file
        if file.endswith('.xlsx') or file.endswith('.xls') or file.endswith('.xlsm'):
            counter+=1
            output_file = os.path.join(output_folder, file)
            file_path = os.path.join(input_folder, file)

            print(f"Processing file {counter}: {file}")
            df = pd.read_excel(file_path, sheet_name='Total Data')
            # df.to_excel(output_file)
            cols = [company_name, dep_level_1, dep_level_2, dep_level_3, dep_level_4, dep_level_5, dep_level_6,
                                job_title]
            companies = df[company_name].unique()

            if not already_fixed: # –ü–µ—Ä–≤–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                if not isinstance(folder_py, str) or not os.path.exists(folder_py):
                    print(f"–ü–∞–ø–∫–∞ {folder_py} —Å –∞–Ω–∫–µ—Ç–∞–º–∏ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                elif os.path.exists(folder_py):
                    for company in companies:
                        print(f"–ò—â–µ–º –∞–Ω–∫–µ—Ç—É —Å –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ {company}")
                        found_files = check_if_past_year_exist(company, folder_py)
                        if found_files:
                            file_to_cmp = os.path.join(folder_py, found_files[0])
                            df_py = pd.read_excel(file_to_cmp, sheet_name=rem_data, header=6)
                            cols_to_copy = [grade]
                            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–º–∏ —Å –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞
                            df = merge_by_cols(df, df_py, cols, cols_to_copy)
                            # df.to_excel('debug.xlsx')
            
                
                # –î–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∏ –Ω–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ
                unfilled = df.loc[df[grade].apply(lambda x: str(x).lower().strip() == 'nan') == True] #add subfunction
                filled = df[~df.index.isin(unfilled.index)]
                empty_count = unfilled.shape[0]

                print(f"–ü—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –≥—Ä–µ–π–¥–æ–≤: {len(filled)}, –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≥—Ä–µ–π–¥–æ–≤: {len(unfilled)}")

                filled_and_processed = process_filled(filled)

                # print(f"DEBUG: {unfilled.loc[5, job_title]}")
                # print(f"shape: {unfilled.shape[0]}")
                df, unfilled_and_processed, count_past_year, count_model = process_unfilled(unfilled, df)
                # print(f"DEBUG: {unfilled_and_processed.loc[5, job_title]}")
                # print(f"shape: {unfilled_and_processed.shape[0]}")
                df.to_excel(output_file, sheet_name='Total Data')
                

                process_output_file(filled_and_processed, unfilled_and_processed, cols, output_file)

                info = {
                    '–§–∞–π–ª—ã —Å –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞': str(found_files) if found_files else '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç',
                    '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≥—Ä–µ–π–¥–æ–≤ –≤ —Ñ–∞–π–ª–µ':  empty_count, 
                    '–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ': df.shape[0],
                    '–ü–æ–¥—Ç—è–Ω—É—Ç–æ –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞': count_past_year,
                    '–ü—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é': count_model
                }

                add_info(info, output_file)
            else: # –ê–Ω–∞–ª–∏—Ç–∏–∫ –ø—Ä–æ–≤–µ—Ä–∏–ª –∏ –∏—Å–ø—Ä–∞–≤–∏–ª –∞–Ω–∫–µ—Ç—É
                
                map_prefill_to_sheet1(file_path, output_file, sheet_prefill='Prefill')
                map_prefill_to_sheet1(file_path, output_file, sheet_prefill='Model')
        print("-----------------------")
        print()



# def map_prefill_to_sheet1(
#     excel_file: str,
#     output_path: str,
#     sheet_prefill: str,
#     match_cols=[company_name, dep_level_1, dep_level_2, dep_level_3, dep_level_4, dep_level_5, dep_level_6, job_title],
#     code_col=grade,               # –æ–∂–∏–¥–∞–µ–º –æ–¥–Ω—É –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (grade) ‚Äî –±–µ–∑ –∫–∞–≤—ã—á–µ–∫, –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –∏–∑–≤–Ω–µ
#     sheet_target='Total Data'
# ):
#     """
#     –î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É—é—â–∞—è –≤–µ—Ä—Å–∏—è: –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç code_col (–Ω–∞–ø—Ä–∏–º–µ—Ä grade) –∏–∑ –ª–∏—Å—Ç–∞ sheet_prefill –≤ sheet_target
#     –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–æ–ª–æ–Ω–æ–∫ match_cols. –ü–µ—á–∞—Ç–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∏ –ø—Ä–∏–º–µ—Ä—ã –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π.
#     """

#     if code_col is None:
#         raise ValueError("–ê—Ä–≥—É–º–µ–Ω—Ç code_col –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω (–ø–µ—Ä–µ–¥–∞–π—Ç–µ grade).")

#     code_col_name = str(code_col)

#     wb = load_workbook(excel_file, read_only=True)
#     if sheet_prefill in wb.sheetnames:

#         # --- —á–∏—Ç–∞–µ–º –æ–±–∞ –ª–∏—Å—Ç–∞ ---
#         df_prefill = pd.read_excel(excel_file, sheet_name=sheet_prefill)
#         df_target = pd.read_excel(excel_file, sheet_name=sheet_target)

#         if sheet_prefill=='Model':
#             df_prefill = df_prefill.drop(columns=grade)
#             df_prefill = df_prefill.rename(columns={'predicted_grade': grade})

#         print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω—ã –ª–∏—Å—Ç—ã: prefill '{sheet_prefill}' ({df_prefill.shape[0]} —Å—Ç—Ä–æ–∫, {df_prefill.shape[1]} –∫–æ–ª–æ–Ω–∫–∏),"
#             f" target '{sheet_target}' ({df_target.shape[0]} —Å—Ç—Ä–æ–∫, {df_target.shape[1]} –∫–æ–ª–æ–Ω–∫–∏)")
#         if df_prefill.shape[0] != 0:
#         # –≤—ã—á–∏—Å–ª–∏–º match_cols –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ prefill –∫—Ä–æ–º–µ code_col_name
#             if match_cols is None:
#                 match_cols = [col for col in df_prefill.columns if col != code_col_name]
#                 print(f"match_cols –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã ‚Äî –∏—Å–ø–æ–ª—å–∑—É—é –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ prefill, –∫—Ä–æ–º–µ '{code_col_name}': {match_cols}")
#             else:
#                 print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ match_cols: {match_cols}")

#             # –ë—ã—Å—Ç—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫
#             missing_in_prefill = [c for c in match_cols if c not in df_prefill.columns]
#             missing_in_target = [c for c in match_cols if c not in df_target.columns]
#             if missing_in_prefill or missing_in_target:
#                 raise KeyError(
#                     "–ù–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ match_cols –Ω–∞–π–¥–µ–Ω—ã.\n"
#                     f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ prefill: {missing_in_prefill}\n"
#                     f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ target: {missing_in_target}"
#                 )

#             if code_col_name not in df_prefill.columns:
#                 raise KeyError(f"–ö–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–¥–æ–º ({code_col_name}) –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ª–∏—Å—Ç–µ {sheet_prefill}.")

#             # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ: —Å–Ω–∞—á–∞–ª–∞ fillna(''), –∑–∞—Ç–µ–º str; –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (strip + lower)
#             def normalize_series(s):
#                 return s.fillna('').astype(str).str.strip().str.lower()

#             for col in match_cols:
#                 df_prefill[col + "_norm"] = normalize_series(df_prefill[col])
#                 df_target[col + "_norm"] = normalize_series(df_target[col])

#             # –¢–∞–∫–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–∞–º code_col (–Ω–æ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–∏–≤–æ–¥–∏—Ç—å –∫ lower)
#             # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è grade –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
#             if code_col_name not in df_target.columns:
#                 df_target[code_col_name] = pd.NA

#             df_prefill[code_col_name] = df_prefill[code_col_name].where(pd.notna(df_prefill[code_col_name]), other=pd.NA)

#             # –°–æ–∑–¥–∞–¥–∏–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π —Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á –¥–ª—è —É–¥–æ–±–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
#             norm_cols = [c + "_norm" for c in match_cols]
#             df_prefill["_merge_key"] = df_prefill[norm_cols].agg("||".join, axis=1)
#             df_target["_merge_key"] = df_target[norm_cols].agg("||".join, axis=1)

#             # –°–∫–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π –≤ –∫–∞–∂–¥–æ–º –Ω–∞–±–æ—Ä–µ?
#             keys_prefill = set(df_prefill["_merge_key"].unique())
#             keys_target = set(df_target["_merge_key"].unique())
#             common_keys = keys_prefill & keys_target

#             print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π (prefill): {len(keys_prefill)}")
#             print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π (target):  {len(keys_target)}")
#             print(f"–û–±—â–∏—Ö –∫–ª—é—á–µ–π (–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ):  {len(common_keys)}")

#             # –ü–æ–∫–∞–∂–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (–∫–ª—é—á–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ target –Ω–æ –Ω–µ—Ç –≤ prefill)
#             missing_keys_in_prefill = list(keys_target - keys_prefill)
#             missing_keys_in_target = list(keys_prefill - keys_target)

#             # –î–µ–ª–∞–µ–º merge –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∫–æ–ª–æ–Ω–∫–∞–º (—á–µ—Ä–µ–∑ _merge_key –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏)
#             # —Å–Ω–∞—á–∞–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ DataFrame —Å –Ω—É–∂–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
#             df_prefill_for_merge = df_prefill[["_merge_key", code_col_name]].rename(columns={code_col_name: f"{code_col_name}_prefill"})
#             df_target_for_merge = df_target.copy()

#             df_merged = df_target_for_merge.merge(
#                 df_prefill_for_merge,
#                 on="_merge_key",
#                 how="left",
#                 indicator=True
#             )

#             if "_merge" in df_merged.columns:
#                 print(df_merged["_merge"].value_counts())
#             else:
#                 print("indicator –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ —Å merge")

#             # –°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –ø–æ–ª—É—á–∏–ª–∏ –Ω–µ–ø—É—Å—Ç–æ–π grade –∏–∑ prefill?
#             df_merged[code_col_name + "_final"] = df_merged[f"{code_col_name}_prefill"].combine_first(df_merged.get(code_col_name))
#             n_prefill_taken = df_merged[f"{code_col_name}_prefill"].notna().sum()
#             print(f"\n–°—Ç—Ä–æ–∫, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞—à—ë–ª—Å—è grade: {n_prefill_taken} –∏–∑ {len(df_merged)}")

#             # –°–æ—Ö—Ä–∞–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ output_path (–∑–∞–º–µ–Ω–∏–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ª–∏—Å—Ç)
#             # —É–¥–∞–ª–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ –∏ –ø—Ä–∏–≤–µ–¥—ë–º –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥—É
#             # –ø–µ—Ä–µ–Ω–µ—Å—ë–º final grade –≤ –∏–º—è code_col_name
#             df_final = df_merged.copy()
#             # –µ—Å–ª–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º target –±—ã–ª–∞ –∫–æ–ª–æ–Ω–∫–∞ code_col_name ‚Äî –∑–∞–º–µ–Ω–∏–º –µ—ë
#             if code_col_name in df_target.columns:
#                 df_final[code_col_name] = df_final[code_col_name + "_final"]
#             else:
#                 df_final[code_col_name] = df_final[code_col_name + "_final"]

#             # –£–¥–∞–ª–∏–º –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–±–∞–≤–ª—è–ª–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏, –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
#             cols_to_drop = [c for c in df_final.columns if c.endswith("_norm") or c.startswith("_merge_key") or c.endswith("_prefill") or c.endswith("_final")]
#             df_final.drop(columns=cols_to_drop, inplace=True, errors='ignore')

#             # –°–æ—Ö—Ä–∞–Ω—è–µ–º excel (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–∏—Å—Ç)
#             os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
#             if not os.path.exists(output_path):
#                 write_mode = "w"
#                 if_sheet_exists=None
#             else:
#                 write_mode = "a"
#                 if_sheet_exists="replace"
#             with pd.ExcelWriter(output_path, engine="openpyxl", mode=write_mode, if_sheet_exists=if_sheet_exists) as writer:
#                 df_final.to_excel(writer, sheet_name=sheet_target, index=False)

#             print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path} (–ª–∏—Å—Ç {sheet_target}).")
#     else:
#         print(f"–õ–∏—Å—Ç {sheet_prefill} –ø—É—Å—Ç.")


# def map_prefill_to_sheet1(
#     excel_file: str,
#     output_path: str,
#     sheet_prefill: str,
#     match_cols=[company_name, dep_level_1, dep_level_2, dep_level_3,
#                 dep_level_4, dep_level_5, dep_level_6, job_title],
#     code_col=grade,
#     sheet_target='Total Data'
# ):
#     """
#     –î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É—é—â–∞—è –≤–µ—Ä—Å–∏—è: –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç code_col
#     –∏–∑ –ª–∏—Å—Ç–∞ sheet_prefill –≤ sheet_target –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–æ–ª–æ–Ω–æ–∫ match_cols.
#     –ù–µ –∏–∑–º–µ–Ω—è–µ—Ç –ª–∏—Å—Ç prefill. –ü–µ—á–∞—Ç–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
#     """

#     if code_col is None:
#         raise ValueError("–ê—Ä–≥—É–º–µ–Ω—Ç code_col –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, grade).")

#     # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å—ë –≤ —Å—Ç—Ä–æ–∫–∏ (–µ—Å–ª–∏ —ç—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã)
#     code_col_name = str(code_col)
#     match_cols = [str(c) for c in match_cols]

#     # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ª–∏—Å—Ç–æ–≤
#     xls = pd.ExcelFile(excel_file)
#     if sheet_prefill not in xls.sheet_names:
#         raise KeyError(f"–õ–∏—Å—Ç '{sheet_prefill}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {excel_file}.")
#     if sheet_target not in xls.sheet_names:
#         raise KeyError(f"–õ–∏—Å—Ç '{sheet_target}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {excel_file}.")

#     # –ß–∏—Ç–∞–µ–º –æ–±–∞ –ª–∏—Å—Ç–∞ (–≤ –ø–∞–º—è—Ç–∏)
#     df_prefill = pd.read_excel(excel_file, sheet_name=sheet_prefill).copy()
#     df_target = pd.read_excel(excel_file, sheet_name=sheet_target).copy()

#     # if sheet_prefill == 'Model':
#     #     # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ predicted_grade –µ—Å—Ç—å ‚Äî –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –µ—ë –≤ grade
#     #     if 'predicted_grade' in df_prefill.columns:
#     #         df_prefill = df_prefill.drop(columns=[code_col_name], errors='ignore')
#     #         df_prefill = df_prefill.rename(columns={'predicted_grade': code_col_name})

#     print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω—ã –ª–∏—Å—Ç—ã: prefill '{sheet_prefill}' ({df_prefill.shape[0]} —Å—Ç—Ä–æ–∫, {df_prefill.shape[1]} –∫–æ–ª–æ–Ω–∫–∏), "
#           f"target '{sheet_target}' ({df_target.shape[0]} —Å—Ç—Ä–æ–∫, {df_target.shape[1]} –∫–æ–ª–æ–Ω–∫–∏)")

#     if df_prefill.empty:
#         print(f"‚ö†Ô∏è –õ–∏—Å—Ç {sheet_prefill} –ø—É—Å—Ç ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
#         return

#     # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
#     missing_in_prefill = [c for c in match_cols if c not in df_prefill.columns]
#     missing_in_target = [c for c in match_cols if c not in df_target.columns]
#     if missing_in_prefill or missing_in_target:
#         raise KeyError(f"–ù–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞–π–¥–µ–Ω—ã.\n"
#                        f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ prefill: {missing_in_prefill}\n"
#                        f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ target: {missing_in_target}")

#     if code_col_name not in df_prefill.columns:
#         raise KeyError(f"–ö–æ–ª–æ–Ω–∫–∞ '{code_col_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ª–∏—Å—Ç–µ {sheet_prefill}.")

#     # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
#     def normalize(s: pd.Series):
#         return s.fillna('').astype(str).str.strip().str.lower()

#     df_prefill_norm = df_prefill.copy()
#     df_target_norm = df_target.copy()

#     for c in match_cols:
#         df_prefill_norm[c + '_norm'] = normalize(df_prefill_norm[c])
#         df_target_norm[c + '_norm'] = normalize(df_target_norm[c])

#     norm_cols = [c + '_norm' for c in match_cols]
#     df_prefill_norm['_merge_key'] = df_prefill_norm[norm_cols].agg('||'.join, axis=1)
#     df_target_norm['_merge_key'] = df_target_norm[norm_cols].agg('||'.join, axis=1)

#     # –°–ª–∏—è–Ω–∏–µ
#     df_prefill_merge = df_prefill_norm[['_merge_key', code_col_name]].rename(
#         columns={code_col_name: f'{code_col_name}_prefill'}
#     )

#     df_merged = df_target_norm.merge(df_prefill_merge, on='_merge_key', how='left', indicator=True)

#     # print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ _merge:")
#     # print(df_merged['_merge'].value_counts().to_string())

#     # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
#     df_merged[f'{code_col_name}_final'] = df_merged[f'{code_col_name}_prefill'].combine_first(df_merged.get(code_col_name))
#     n_updated = df_merged[f'{code_col_name}_prefill'].notna().sum()
#     print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏ –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ {n_updated} –∑–Ω–∞—á–µ–Ω–∏–π {code_col_name} –∏–∑ {len(df_merged)} —Å—Ç—Ä–æ–∫.")

#     # –§–∏–Ω–∞–ª—å–Ω—ã–π DataFrame (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫)
#     df_final = df_merged.copy()
#     df_final[code_col_name] = df_final[f'{code_col_name}_final']
#     cols_to_drop = [c for c in df_final.columns if c.endswith('_norm')
#                     or c.startswith('_merge_key')
#                     or c.endswith('_prefill')
#                     or c.endswith('_final')
#                     or c == '_merge']
#     df_final.drop(columns=cols_to_drop, inplace=True, errors='ignore')

#     # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Excel
#     os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)


#     with pd.ExcelWriter(output_path, engine='openpyxl', mode='a', if_sheet_exists="replace") as writer:
#         df_final.to_excel(writer, sheet_name=sheet_target, index=False)

#     print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path} (–ª–∏—Å—Ç '{sheet_target}').")


def map_prefill_to_sheet1(
    excel_file: str,
    output_path,
    sheet_prefill,
    match_cols=[company_name, dep_level_1, dep_level_2, dep_level_3, dep_level_4, dep_level_5, dep_level_6, job_title],
    code_cols=[grade],
    sheet_target='Total Data'
):
    """
    –ú–∞–ø–ø–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–¥–æ–≤ –∏–∑ –ª–∏—Å—Ç–∞ Prefill –Ω–∞ –¥–∞–Ω–Ω—ã–µ –≤ –ª–∏—Å—Ç–µ Sheet1 –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–æ–ª–æ–Ω–æ–∫.
    """

    # --- —á–∏—Ç–∞–µ–º –æ–±–∞ –ª–∏—Å—Ç–∞ ---
    df_prefill = pd.read_excel(excel_file, sheet_name=sheet_prefill)
    df_target = pd.read_excel(excel_file, sheet_name=sheet_target)

    if match_cols is None:
        match_cols = [col for col in df_prefill.columns if col not in code_cols]

    # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫ —Å—Ç—Ä–æ–∫–µ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    for col in match_cols:
        if col in df_prefill.columns:
            df_prefill[col] = df_prefill[col].astype(str).fillna('')
        if col in df_target.columns:
            df_target[col] = df_target[col].astype(str).fillna('')

    if set(match_cols).issubset(df_prefill.columns) and set(match_cols).issubset(df_target.columns):
        df_merged = df_target.merge(
            df_prefill[match_cols + list(code_cols)],
            on=match_cols,
            how='left',
            suffixes=('', '_prefill')
        )

        # --- –∑–∞–º–µ–Ω—è–µ–º –∫–æ–¥—ã –∏–∑ Prefill, –µ—Å–ª–∏ —Ç–∞–º –µ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è ---
        for col in code_cols:
            df_merged[col] = df_merged[f"{col}_prefill"].combine_first(df_merged[col])
            df_merged.drop(columns=f"{col}_prefill", inplace=True)

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if not os.path.exists(output_path):
            with pd.ExcelWriter(output_path, engine="openpyxl", mode="w") as writer:
                df_merged.to_excel(writer, sheet_name=sheet_target, index=False)
        else:
            with pd.ExcelWriter(output_path, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
                df_merged.to_excel(writer, sheet_name=sheet_target, index=False)

        print(f"–ù–∞ –ª–∏—Å—Ç '{sheet_target}' –ø–æ–¥—Ç—è–Ω—É—Ç—ã –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –ª–∏—Å—Ç–∞ '{sheet_prefill}' –≤ —Ñ–∞–π–ª–µ {excel_file}")
    else:
        print("–ù–µ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ match_cols –Ω–∞–π–¥–µ–Ω—ã –≤ –æ–±–æ–∏—Ö –ª–∏—Å—Ç–∞—Ö.")


        
def add_info(info, output_file):
    info = pd.DataFrame(data=[info])
    book = load_workbook(output_file)

    ws3 = book.create_sheet(title='Info')

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
    for col_idx, col_name in enumerate(info.columns, start=1):
        ws3.cell(row=1, column=col_idx, value=col_name)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏
    for row in info.itertuples(index=False):
        excel_row = ws3.max_row + 1
        for col_idx, value in enumerate(row, start=1):
            ws3.cell(row=excel_row, column=col_idx, value=value)
    book.save(output_file)


def process_output_file(df1, df2, cols, output_file, sheet1_name='Prefill', sheet2_name='Model'):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –¥–≤–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π Excel-—Ñ–∞–π–ª.
    –í df1 –ø–æ–¥—Å–≤–µ—á–∏–≤–∞–µ—Ç –∫—Ä–∞—Å–Ω—ã–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ past_year_check == False.
    –í df2 –ø–æ–¥—Å–≤–µ—á–∏–≤–∞–µ—Ç –∫—Ä–∞—Å–Ω—ã–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ function_confidence < 70.
    """

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    df1 = df1.drop_duplicates(subset=cols)
    df2 = df2.drop_duplicates(subset=cols)

    if 'grade_old' in df1.columns:
        # print(1)
        df1 = df1.loc[:, [company_name,'–°–µ–∫—Ç–æ—Ä', function_code, subfunction_code, specialization_code, grade,
               'past_year_check', dep_level_1, dep_level_2, dep_level_3, dep_level_4, dep_level_5, dep_level_6,
                                job_title, 'grade_old']]
    else:
        # print(2)
        df1 = df1.loc[:, [company_name,'–°–µ–∫—Ç–æ—Ä', function_code, subfunction_code, specialization_code, grade,
                        dep_level_1,
        dep_level_2, dep_level_3, dep_level_4, dep_level_5, dep_level_6,
                        job_title]]
    
    if len(df2.columns)>1:
        if 'prediction_confidence' in df2.columns:
            # print(3)
            df2 = df2.loc[:, [company_name, function_code, subfunction_code, specialization_code, grade,
                'prediction_confidence',
                    dep_level_1, dep_level_2, dep_level_3, dep_level_4, dep_level_5, dep_level_6,
                                    job_title]]
        else:
            # print(4)
            df2 = df2.loc[:, [company_name, function_code, subfunction_code, specialization_code,
                    dep_level_1, dep_level_2, dep_level_3, dep_level_4, dep_level_5, dep_level_6,
                                    job_title]]

    book = load_workbook(output_file)
    red_fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')

    # –†–∞–±–æ—Ç–∞ —Å df1
    ws1 = book.create_sheet(title=sheet1_name)
    for col_idx, col_name in enumerate(df1.columns, start=1):
        ws1.cell(row=1, column=col_idx, value=col_name)

    for _, row in df1.iterrows():
        excel_row = ws1.max_row + 1
        highlight = row.get('past_year_check') is False

        for col_idx, value in enumerate(row, start=1):
            cell = ws1.cell(row=excel_row, column=col_idx, value=value)
            if highlight:
                cell.fill = red_fill

    # –†–∞–±–æ—Ç–∞ —Å df2
    ws2 = book.create_sheet(title=sheet2_name)
    for col_idx, col_name in enumerate(df2.columns, start=1):
        ws2.cell(row=1, column=col_idx, value=col_name)

    for _, row in df2.iterrows():
        excel_row = ws2.max_row + 1
        try:
            s = str(row.get('prediction_confidence'))
            num = float(s.rstrip('%'))
            highlight = num < 0.7
        except:
            highlight = False

        for col_idx, value in enumerate(row, start=1):
            cell = ws2.cell(row=excel_row, column=col_idx, value=value)
            if highlight:
                cell.fill = red_fill

    book.save(output_file)
    print(f"–õ–∏—Å—Ç—ã '{sheet1_name}' –∏ '{sheet2_name}' –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ñ–∞–π–ª: {output_file}")

def process_unfilled(df, df_orig):
    # –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –∫–æ–¥—ã –ø—Ä–æ—à–ª—ã—Ö –ª–µ—Ç –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    count_past_year = 0
    preds = pd.DataFrame()

    if 'grade_old' in df_orig.columns:
        df_orig[function_code].update(df['grade_old'])
    
    # print("DEBUG 2: ", df_orig.loc[5, job_title])
    df_without_py = df_orig.loc[df_orig[grade].apply(lambda x: str(x).lower().strip() == 'nan') == True]
    count_model = df_without_py.shape[0]
    count_past_year = df.shape[0] - count_model
    # –¢–∞–º –≥–¥–µ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞ –Ω–µ—Ç, –ø—Ä–æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ–π—Ä–æ–Ω–∫–æ–π
    if count_model != 0:
        preds = predict_grades(df_without_py)
        preds = preds.loc[preds[company_name].apply(lambda x: str(x).lower().strip() == 'nan') == False]

    return df_orig, preds, count_past_year, count_model
    

def process_filled(df):
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å—Ç–æ–ª–±—Ü—ã grade –∏ 'grade_old' –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ.
    –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü 'past_year_check', –≥–¥–µ:
      - True, –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–≤–ø–∞–¥–∞—é—Ç,
      - True, –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ func_old == NaN,
      - False ‚Äî –µ—Å–ª–∏ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è.
    """
    df = df.copy()
    df["past_year_check"] = True

    if "grade_old" in df.columns:
        df["past_year_check"] = (
            (df[grade] == df["grade_old"]) |
            (df["grade_old"].isna())
        )
    return df


def merge_by_cols(df, df_py, cols, cols_to_copy):
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ df –∏ df_py –ø–æ —Å–ø–∏—Å–∫—É –∫–æ–ª–æ–Ω–æ–∫ cols.
    –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚Äî –∫–æ–ø–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ cols_to_copy –∏–∑ df_py –≤ df –≤ –∫–æ–ª–æ–Ω–∫—É grade_old.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        df (pd.DataFrame): –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º, –≤ –∫–æ—Ç–æ—Ä—ã–π –∫–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        df_py (pd.DataFrame): –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö
        cols (list): —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        cols_to_copy (list): —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–∑ df_py –≤ df (–æ–∂–∏–¥–∞–µ—Ç—Å—è –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞: ['grade'])

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        pd.DataFrame: –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π df
    """

    # –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    missing_cols = [c for c in cols + cols_to_copy if c not in df_py.columns]
    if missing_cols:
        raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ df_py: {missing_cols}")

    df = df.copy()
    df_py = df_py.copy()

    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫ —Å—Ç—Ä–æ–∫–µ (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å ValueError –ø—Ä–∏ merge)
    for c in cols:
        df[c] = df[c].astype(str).replace('nan', np.nan)
        df_py[c] = df_py[c].astype(str).replace('nan', np.nan)

    # –£–±–µ—Ä—ë–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º –≤ df_py
    df_py_unique = df_py.drop_duplicates(subset=cols, keep="first")

    # –í—ã–ø–æ–ª–Ω–∏–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    df_merged = df.merge(
        df_py_unique[cols + cols_to_copy],
        on=cols,
        how="left",
        suffixes=("", "_py")
    )

    # –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–Ω–æ—Å–∏–º –¥–∞–Ω–Ω—ã–µ –∏–∑ df_py –≤ grade_old
    old_col = cols_to_copy[0]  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "grade"
    py_col = f"{old_col}_py"

    if py_col in df_merged.columns:
        df_merged["grade_old"] = df_merged[py_col]
        df_merged.drop(columns=[py_col], inplace=True)
    else:
        df_merged["grade_old"] = np.nan

    return df_merged


# def _normalize_val(v):
#     """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: –Ω–∞ str, strip –∏ lower (None/NaN -> '')"""
#     if pd.isna(v):
#         return ""
#     s = str(v).strip()
#     return s.lower()

def check_if_past_year_exist(company, folder_py):
    company_str = str(company).strip()
    found_files = []

    for filename in os.listdir(folder_py):
        if company_str.lower() in filename.lower():
            found_files.append(filename)
    
    if found_files:
        for f in found_files:
            print(f"–ù–∞–π–¥–µ–Ω–∞ –∞–Ω–∫–µ—Ç–∞ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞: {f}")
    else:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞–Ω–∫–µ—Ç –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞.")
    return found_files