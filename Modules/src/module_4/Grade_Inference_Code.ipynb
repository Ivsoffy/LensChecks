{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "663bf66f-d435-4221-9b0a-7df4e0f99501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jp-OutputArea-output .progress-bar {\n",
       "    background-color: #22709C \n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Starting grade model inference...\n",
      "Loading encoders and model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilya_\\anaconda3\\envs\\LensDigital\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Loading best model from model/Grade_best_f1_model.pth\n",
      "Loading data for inference...\n",
      "\n",
      "Processing Afisha_SDF_2025.xlsx\n",
      "Running inference...\n",
      "Tokenizing job titles...\n",
      "Number of unique job titles: 70\n",
      "Running inference on 186 samples in 2 batches...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53d9971611f48a48b45e69f57406e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/Afisha_grade_inference.xlsx\n",
      "\n",
      "Inference Summary:\n",
      "Processed 186 records\n",
      "Number of unique predicted grades: 10\n",
      "Grade distribution:\n",
      "predicted_grade\n",
      "15.0    48\n",
      "14.0    40\n",
      "12.0    27\n",
      "13.0    23\n",
      "16.0    21\n",
      "17.0    11\n",
      "18.0     6\n",
      "20.0     5\n",
      "11.0     4\n",
      "23.0     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Inference completed in 12.65 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import Feature_buildnew as fb\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Torch was not compiled with flash attention.*\", category=UserWarning)\n",
    "\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".jp-OutputArea-output .progress-bar {\n",
    "    background-color: #22709C \n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "# Check if CUDA is available and set the device to GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define model directory and tag\n",
    "my_directory = 'model'  # Same as training\n",
    "tag = \"Grade\"  # Same as training\n",
    "\n",
    "# Define the model class (needs to be identical to the training model definition)\n",
    "class GradePredictionModel(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes_list, num_numerical_features, num_grade_classes, dropout_rate=0.3):\n",
    "        super(GradePredictionModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Embeddings for categorical features\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_classes, self.bert.config.hidden_size)\n",
    "            for num_classes in num_classes_list\n",
    "        ])\n",
    "        \n",
    "        # Calculate the combined dimension\n",
    "        combined_dim = self.bert.config.hidden_size * (len(num_classes_list) + 1) + num_numerical_features\n",
    "        \n",
    "        # Deeper network with multiple layers\n",
    "        self.fc1 = nn.Linear(combined_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, num_grade_classes)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, categorical, numerical):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Embed categorical features\n",
    "        embedded_features = [embedding(categorical[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
    "        \n",
    "        # Combine all features\n",
    "        combined_output = torch.cat([pooled_output] + embedded_features + [numerical], dim=1)\n",
    "        \n",
    "        # Forward through deep network\n",
    "        x = self.fc1(combined_output)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final layer\n",
    "        grade = self.fc3(x)\n",
    "        return grade\n",
    "\n",
    "# Function to encode text using BERT tokenizer\n",
    "def bert_encode(texts, tokenizer, max_len=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    \n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# Inference function\n",
    "def run_inference(df, model, tokenizer, encoders, le_grade, batch_size=128):\n",
    "    \"\"\"\n",
    "    Run inference on the provided dataframe\n",
    "    \n",
    "    Args:\n",
    "        df: Dataframe with features\n",
    "        model: Trained model\n",
    "        tokenizer: BERT tokenizer\n",
    "        encoders: Dictionary of label encoders for categorical features\n",
    "        le_grade: Label encoder for grade classes\n",
    "        batch_size: Batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe with predictions and probabilities\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    # Define the features as in training\n",
    "    categorical_features = ['function', 'subfunction', 'spec', 'industry', 'region', 'headcount_cat', 'revenue_cat']\n",
    "    numerical_features = ['Scaled_Logged_BP','Scaled_Logged_BP_Region', 'FtC','SUtC','SPtC','SUtF','SPtSU', 'functions_num',\n",
    "                          'subfunctions_num', 'spec_num','Scaled_EmpBP_Portion_C','Scaled_EmpBP_Portion_F','Scaled_EmpBP_Portion_SU',\n",
    "                          'Scaled_EmpBP_Portion_SP','Scaled_emp_in_job','Scaled_emp_in_job_r','Scaled_CR_C','Scaled_CR_F','Scaled_CR_SU',\n",
    "                          'Scaled_CR_SP','Scaled_CR_C_R','Scaled_CR_F_R','Scaled_CR_SU_R','Scaled_CR_SP_R']\n",
    "    \n",
    "    # Encode categorical features\n",
    "    X_categorical = []\n",
    "    for feature in categorical_features:\n",
    "        encoder = encoders[feature]\n",
    "        # Handle potential new categories not seen in training\n",
    "        encoded_feature = []\n",
    "        for value in df[feature]:\n",
    "            try:\n",
    "                encoded_value = encoder.transform([value])[0]\n",
    "            except:\n",
    "                # Assign a default value (0) for new categories not seen during training\n",
    "                encoded_value = 0\n",
    "                print(f\"Warning: New category '{value}' found in '{feature}' - using default encoding\")\n",
    "            encoded_feature.append(encoded_value)\n",
    "        X_categorical.append(encoded_feature)\n",
    "    \n",
    "    X_categorical = np.array(X_categorical).T\n",
    "    \n",
    "    # Extract numerical features\n",
    "    X_numerical = df[numerical_features].values\n",
    "    \n",
    "    # Tokenize job titles with progress bar\n",
    "    print(\"Tokenizing job titles...\")\n",
    "    unique_job_titles = df['job_title'].unique()\n",
    "    print(f\"Number of unique job titles: {len(unique_job_titles)}\")\n",
    "    \n",
    "    unique_input_ids, unique_attention_masks = bert_encode(unique_job_titles, tokenizer)\n",
    "    \n",
    "    # Create a dictionary mapping job titles to their tokenized values\n",
    "    tokenized_mapping = {job_title: (input_id, attention_mask) for job_title, input_id, attention_mask in \n",
    "                         zip(unique_job_titles, unique_input_ids, unique_attention_masks)}\n",
    "    \n",
    "    # Map tokenized values back to the original DataFrame\n",
    "    X_input_ids = torch.stack([tokenized_mapping[job_title][0] for job_title in df['job_title']])\n",
    "    X_attention_masks = torch.stack([tokenized_mapping[job_title][1] for job_title in df['job_title']])\n",
    "\n",
    "    # for job_title in df['job_title']:\n",
    "    #     print(job_title)\n",
    "    #     print(X_input_ids)\n",
    "    #     print(X_attention_masks)\n",
    "        \n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    num_samples = len(df)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"Running inference on {num_samples} samples in {num_batches} batches...\")\n",
    "    progress_bar = tqdm(total=num_batches, desc=\"Processing batches\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            \n",
    "            # Get batch data\n",
    "            batch_input_ids = X_input_ids[start_idx:end_idx].to(device)\n",
    "            batch_attention_masks = X_attention_masks[start_idx:end_idx].to(device)\n",
    "            batch_categorical = torch.tensor(X_categorical[start_idx:end_idx], dtype=torch.long).to(device)\n",
    "            batch_numerical = torch.tensor(X_numerical[start_idx:end_idx], dtype=torch.float).to(device)\n",
    "            \n",
    "            # Run model\n",
    "            grade_pred = model(batch_input_ids, batch_attention_masks, batch_categorical, batch_numerical)\n",
    "            \n",
    "            # Get predicted classes and probabilities\n",
    "            probabilities = torch.softmax(grade_pred, dim=1)\n",
    "            predictions = torch.argmax(grade_pred, dim=1)\n",
    "            \n",
    "            # Move to CPU and convert to numpy\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            \n",
    "            progress_bar.update(1)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Convert predictions back to original grade labels\n",
    "    predicted_grades = le_grade.inverse_transform(all_predictions)\n",
    "    \n",
    "    # Add predictions to the dataframe\n",
    "    df_result = df.copy()\n",
    "    df_result['predicted_grade'] = predicted_grades\n",
    "    df_result['predicted_grade_encoded'] = all_predictions\n",
    "    \n",
    "    # Add top-3 predicted grades and their probabilities\n",
    "    top_k = 3\n",
    "    \n",
    "    # Find indices of top-k probabilities for each prediction\n",
    "    all_probs = np.array(all_probabilities)\n",
    "    topk_indices = np.argsort(-all_probs, axis=1)[:, :top_k]\n",
    "    \n",
    "    # Extract corresponding grades and probabilities\n",
    "    for i in range(top_k):\n",
    "        # Skip if we don't have enough classes\n",
    "        if i >= all_probs.shape[1]:\n",
    "            continue\n",
    "            \n",
    "        grade_idx = topk_indices[:, i]\n",
    "        probs = np.array([all_probs[j, idx] for j, idx in enumerate(grade_idx)])\n",
    "        \n",
    "        grade_labels = le_grade.inverse_transform(grade_idx)\n",
    "        \n",
    "        df_result[f'top{i+1}_grade'] = grade_labels\n",
    "        df_result[f'top{i+1}_probability'] = probs\n",
    "    \n",
    "    # Calculate confidence (probability of the top prediction)\n",
    "    df_result['prediction_confidence'] = [all_probs[i, pred] for i, pred in enumerate(all_predictions)]\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "# Main inference function\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    print(\"Starting grade model inference...\")\n",
    "    \n",
    "    # Load model components\n",
    "    print(\"Loading encoders and model files...\")\n",
    "    \n",
    "    # Load the BERT tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "    \n",
    "    # Load label encoders\n",
    "    categorical_features = ['function', 'subfunction', 'spec', 'industry', 'region', 'headcount_cat', 'revenue_cat']\n",
    "    encoders = {}\n",
    "    for feature in categorical_features:\n",
    "        encoders[feature] = joblib.load(f'{my_directory}/{tag}_le_{feature}.pkl')\n",
    "    \n",
    "    le_grade = joblib.load(f'{my_directory}/{tag}_le_grade.pkl')\n",
    "    \n",
    "    # Get number of classes for each categorical feature\n",
    "    num_classes_list = [len(encoder.classes_) for encoder in encoders.values()]\n",
    "    num_grade_classes = len(le_grade.classes_)\n",
    "    \n",
    "    # Define the number of numerical features\n",
    "    numerical_features = ['Scaled_Logged_BP','Scaled_Logged_BP_Region', 'FtC','SUtC','SPtC','SUtF','SPtSU', 'functions_num',\n",
    "                          'subfunctions_num', 'spec_num','Scaled_EmpBP_Portion_C','Scaled_EmpBP_Portion_F','Scaled_EmpBP_Portion_SU',\n",
    "                          'Scaled_EmpBP_Portion_SP','Scaled_emp_in_job','Scaled_emp_in_job_r','Scaled_CR_C','Scaled_CR_F','Scaled_CR_SU',\n",
    "                          'Scaled_CR_SP','Scaled_CR_C_R','Scaled_CR_F_R','Scaled_CR_SU_R','Scaled_CR_SP_R']\n",
    "    \n",
    "    num_numerical_features = len(numerical_features)\n",
    "    \n",
    "    # Initialize the model\n",
    "    print(\"Initializing model...\")\n",
    "    model = GradePredictionModel(bert_model, num_classes_list, num_numerical_features, num_grade_classes).to(device)\n",
    "    \n",
    "    # Load the best model weights\n",
    "    best_model_path = f\"{my_directory}/{tag}_best_f1_model.pth\"\n",
    "    print(f\"Loading best model from {best_model_path}\")\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = 'results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    input_dir = 'files'\n",
    "    \n",
    "    # Load and process the data\n",
    "    print(\"Loading data for inference...\")\n",
    "    \n",
    "    # ===============================================================\n",
    "    # PLACEHOLDER: Load and transform your data here\n",
    "    # Example:\n",
    "    # df = pd.read_csv('your_data.csv')\n",
    "    # \n",
    "    # Implement any necessary transformations to match the training data\n",
    "    # The dataframe must contain the following columns:\n",
    "    # - 'job_title': for BERT encoding\n",
    "    # - categorical_features: ['function', 'subfunction', 'spec', 'industry', 'region', 'headcount_cat', 'revenue_cat']\n",
    "    # - numerical_features: as defined in the variable numerical_features\n",
    "    # ===============================================================\n",
    "    \n",
    "    # LOAD YOUR DATA HERE\n",
    "    # Process each file in the input folder\n",
    "   \n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.xlsx'):\n",
    "    \n",
    "            print(f\"\\nProcessing {file_name}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "            \n",
    "            df = pd.read_excel(file_path, sheet_name=\"Данные\", header=6)\n",
    "            df_info = pd.read_excel(file_path, sheet_name=\"Общая информация\", header=1)\n",
    "    \n",
    "            column = 'Название компании (заполняется автоматически)'\n",
    "            \n",
    "            if column in df.columns:\n",
    "                \n",
    "                # Rename a single column\n",
    "                df.rename(columns={'Название компании (заполняется автоматически)': 'company'}, inplace=True)\n",
    "    \n",
    "                industry = df_info.iloc[1, 3]\n",
    "                headcount = df_info.iloc[3, 3]\n",
    "                revenue = df_info.iloc[4, 3]\n",
    "                company_name = df_info.iloc[0,3]\n",
    "                \n",
    "            else:\n",
    "                # Rename a single column\n",
    "                df.rename(columns={'Название компании на английском языке': 'company'}, inplace=True)\n",
    "                \n",
    "                industry = df_info.iloc[1, 3]\n",
    "                headcount = df_info.iloc[7, 3]\n",
    "                revenue = df_info.iloc[8, 3]\n",
    "                company_name = df_info.iloc[0,3]\n",
    "    \n",
    "            df['industry'] = industry\n",
    "            df['headcount_cat'] = headcount\n",
    "            df['revenue_cat'] = revenue\n",
    "            \n",
    "    \n",
    "            # df = df.dropna(subset=['Базовый оклад (BP)'])\n",
    "            \n",
    "            # Apply feature calculation using calculate_f function\n",
    "            df = fb.calculate_f(df)\n",
    "\n",
    "            # print(df['job_title'].unique())\n",
    "\n",
    "            \n",
    "            \n",
    "    \n",
    "            # YOUR DATA TRANSFORMATION CODE HERE\n",
    "            \n",
    "            # ===============================================================\n",
    "            # End of PLACEHOLDER\n",
    "            # ===============================================================\n",
    "            \n",
    "            # Run inference\n",
    "            print(\"Running inference...\")\n",
    "            df_with_predictions = run_inference(df, model, tokenizer, encoders, le_grade)\n",
    "\n",
    "            df_with_predictions = df_with_predictions[['company', 'Подразделение 1 уровня','Подразделение 2 уровня','Подразделение 3 уровня',\n",
    "                                                       'Подразделение 4 уровня','Подразделение 5 уровня','Подразделение 6 уровня','job_title',\n",
    "                                                       'Код сотрудника','Код руководителя сотрудника','Руководитель / специалист',\n",
    "                                                       'Оценка эффективности работы сотрудника','Уровень подчинения по отношению к Первому лицу компании',\n",
    "                                                       'Экспат','Пол','Год рождения','Дата приема на работу','Сотрудники, проработавшие в компании меньше 1 года',\n",
    "                                                       'Название города','region','Внутренний грейд компании','grade', 'predicted_grade', 'prediction_confidence','function','subfunction','spec',\n",
    "                                                       'Название функции (заполняется автоматически)','Название подфункции (заполняется автоматически)',\n",
    "                                                       'Название специализации (заполняется автоматически)','Размер ставки','Ежемесячный оклад',\n",
    "                                                       'Число окладов в году','Постоянные надбавки и доплаты (общая сумма за год)','Право на получение переменного вознаграждения',\n",
    "                                                       'Фактическая премия','Целевая премия (%)','Право на участие в Программе долгосрочного вознаграждения (LTIP)','Фактическая стоимость всех предоставленных типов LTI за 1 год',\n",
    "                                                       'Целевая стоимость всех предоставленных типов LTI в % от базового оклада за 1 год',\n",
    "                                                       'Тип программы 1','Фактическая стоимость вознаграждения 1 за 1 год','Целевая стоимость вознаграждения 1 как % от базового оклада за 1 год',\n",
    "                                                       'Частота выплат 1','Тип программы 2','Фактическая стоимость вознаграждения 2 за 1 год','Целевая стоимость вознаграждения 2 как % от базового оклада за 1 год',\n",
    "                                                       'Частота выплат 2','Тип программы 3','Фактическая стоимость вознаграждения 3 за 1 год','Целевая стоимость вознаграждения 3 как % от базового оклада за 1 год',\n",
    "                                                       'Частота выплат 3','Комментарии','Годовой оклад (AP)','BP','Краткосрочное фактическое переменное вознаграждение (VP)','Целевая Премия (TI)',\n",
    "                                                       'Фактическое совокупное вознаграждение (TC)','Целевое совокупное вознаграждение (TTC)','Фактическое долгосрочное вознаграждение (LTIP)',\n",
    "                                                       'Целевое долгосрочное вознаграждение (TLTIP)','Прямое совокупное вознаграждение (TDC)','Целевое прямое совокупное вознаграждение (TTDC)']]\n",
    "\n",
    "            df_with_predictions = df_with_predictions.rename(columns={'company': 'Название компании (заполняется автоматически)',\n",
    "                                                                     'job_title': 'Название должности',\n",
    "                                                                     'region': 'Регион/область (заполняется автоматически)',\n",
    "                                                                     'grade': 'Грейд / Уровень обзора',\n",
    "                                                                     'function': 'Код функции',\n",
    "                                                                     'subfunction': 'Код подфункции',\n",
    "                                                                     'spec': 'Код специализации',\n",
    "                                                                     'BP': 'Базовый оклад (BP)'})\n",
    "\n",
    "            \n",
    "            # Save results\n",
    "            # output_path = f\"{output_dir}/{company_name}_inference_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "            output_path = f\"{output_dir}/{company_name}_grade_inference.xlsx\"\n",
    "\n",
    "            # Записываем оба DataFrame-ы на отдельные листы в одном Excel файле.\n",
    "            with pd.ExcelWriter(output_path) as writer:\n",
    "                df_info.to_excel(writer, sheet_name=\"Общая информация\", startrow=2, startcol=1, header=False, index=False)\n",
    "                df_with_predictions.to_excel(writer, sheet_name='Данные', index=False)\n",
    "            \n",
    "            print(f\"Results saved to {output_path}\")\n",
    "            \n",
    "            # Print summary\n",
    "            print(\"\\nInference Summary:\")\n",
    "            print(f\"Processed {len(df_with_predictions)} records\")\n",
    "            print(f\"Number of unique predicted grades: {df_with_predictions['predicted_grade'].nunique()}\")\n",
    "            print(f\"Grade distribution:\")\n",
    "            print(df_with_predictions['predicted_grade'].value_counts().head(10))\n",
    "            \n",
    "            # Calculate and print elapsed time\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"\\nInference completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe06d9-9d4c-45a3-9cc0-6e40c760f285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LensDigital]",
   "language": "python",
   "name": "conda-env-LensDigital-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
